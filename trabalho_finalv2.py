# -*- coding: utf-8 -*-
"""
TRABALHO FINAL - APRENDIZADO DE M√ÅQUINA
=======================================

Pipeline Completo de Ci√™ncia de Dados para Classifica√ß√£o de Ratings de Jogos Steam

Disciplina: Aprendizado de M√°quina
Autores: Gustavo Gonzaga dos Santos, Thiago Gonzaga dos Santos
Data: 25 de junho de 2025

PROBLEMA: Classifica√ß√£o supervisionada de ratings de jogos Steam
DATASET: Steam Games Dataset (50,000+ registros)
OBJETIVO: Desenvolver modelo para classificar ratings baseado em caracter√≠sticas dos jogos

PIPELINE IMPLEMENTADO:
    1. Coleta de dados
2. An√°lise explorat√≥ria dos dados  
3. Limpeza dos dados
4. Convers√£o de tipos e formata√ß√£o
5. Tratamento de outliers
6. Codifica√ß√£o de vari√°veis categ√≥ricas
7. Escalonamento de vari√°veis
8. Sele√ß√£o e cria√ß√£o de atributos
9. Balanceamento de classes
10. Redu√ß√£o de dimensionalidade
11. Divis√£o dos dados
12. Treinamento do modelo
13. Avalia√ß√£o do modelo
14. Ajuste de hiperpar√¢metros
15. Testes finais e valida√ß√£o
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score
from sklearn.preprocessing import LabelEncoder, RobustScaler
from imblearn.over_sampling import SMOTE
from sklearn.metrics import accuracy_score, f1_score

import warnings
warnings.filterwarnings('ignore')

class PipelineTrabalhoFinal:

    def __init__(self):
        self.dados_originais = None
        self.X_final = None
        self.y_final = None
        self.modelos = {}
        self.melhor_modelo = None
        self.resultados_finais = {}
        self.scaler = RobustScaler()
        self.le = LabelEncoder()
        
        plt.switch_backend('Agg')  # Se n√£o houver interface gr√°fica, para n√£o travar

        print("üéì TRABALHO FINAL - PIPELINE DE CI√äNCIA DE DADOS INICIALIZADO")
        print("=" * 80)

    def etapa1_coleta_dados(self, caminho='games.csv'):
        """
        ETAPA 1: COLETA DE DADOS
        
        Carrega o dataset de jogos Steam e realiza verifica√ß√µes iniciais
        """
        print("\nETAPA 1: COLETA DE DADOS")
        print("-" * 50)
        try:
            self.dados_originais = pd.read_csv(caminho)
            print(f"‚úÖ Dataset carregado com sucesso!")
            print(f"   Arquivo: {caminho}")
            print(f"   Dimens√µes: {self.dados_originais.shape}")
            print(f"   Colunas: {list(self.dados_originais.columns)}\n")

            # Plot 1: Contagem de linhas vs colunas
            plt.figure(figsize=(5, 3))
            plt.bar(["Registros", "Colunas"], [self.dados_originais.shape[0], self.dados_originais.shape[1]], color=['blue', 'green'])
            plt.title("Dimens√µes do Dataset")
            plt.savefig("plot_etapa1_dim.png", dpi=100, bbox_inches='tight')
            plt.close()

            return True
        except Exception as e:
            print(f"‚ùå Erro ao carregar dados: {e}")
            return False
        
    def etapa2_analise_exploratoria(self):
        """
        ETAPA 2: AN√ÅLISE EXPLORAT√ìRIA DOS DADOS
        
        Realiza an√°lise detalhada para entender o dataset
        """
        print("\nETAPA 2: AN√ÅLISE EXPLORAT√ìRIA DOS DADOS")
        print("-" * 50)
        
        # Tipos de dados + valores ausentes
        print("TIPOS DE DADOS:")
        print(self.dados_originais.dtypes)

        print("\nVALORES AUSENTES:")
        ausentes = self.dados_originais.isnull().sum()
        if ausentes.sum() == 0:
            print("   Nenhum valor ausente encontrado!")
        else:
            print(ausentes[ausentes>0])

        # An√°lise da vari√°vel alvo "rating"
        print("\nAN√ÅLISE DA VARI√ÅVEL TARGET (rating):")
        print(self.dados_originais['rating'].value_counts())

        # Plot 2: Distribui√ß√£o do rating
        plt.figure(figsize=(5,3))
        sns.countplot(data=self.dados_originais, x='rating', order=self.dados_originais['rating'].value_counts().index)
        plt.title("Distribui√ß√£o de 'rating'")
        plt.xticks(rotation=45)
        plt.tight_layout()
        plt.savefig("plot_etapa2_rating.png", dpi=100, bbox_inches='tight')
        plt.close()

        # Estat√≠sticas descritivas
        print("\nESTAT√çSTICAS DESCRITIVAS (Vari√°veis Num√©ricas):")
        num_cols = self.dados_originais.select_dtypes(include=[np.number]).columns
        print(self.dados_originais[num_cols].describe())

        # Plot 3: Matriz de correla√ß√£o
        plt.figure(figsize=(5, 4))
        corr = self.dados_originais[num_cols].corr()
        sns.heatmap(corr, annot=False, cmap='Blues')
        plt.title("Matriz de Correla√ß√£o (Bruta)")
        plt.savefig("plot_etapa2_corr.png", dpi=100, bbox_inches='tight')
        plt.close()

    def etapa3_limpeza_dados(self):
        """
        ETAPA 3: LIMPEZA DOS DADOS
        
        Remove registros inv√°lidos e trata inconsist√™ncias
        """
        print("\nETAPA 3: LIMPEZA DOS DADOS")
        print("-" * 50)
        registros_iniciais = len(self.dados_originais)
        # Remover colunas identificadoras
        cols_remover = ['app_id', 'title', 'date_release']
        existentes = [c for c in cols_remover if c in self.dados_originais.columns]
        if existentes:
            print(f"Removidas colunas identificadoras: {existentes}")
            self.dados_originais.drop(columns=existentes, inplace=True)

        # Remover linhas com valores ausentes
        antes = len(self.dados_originais)
        self.dados_originais.dropna(inplace=True)
        removidos = antes - len(self.dados_originais)

        print(f"   Registros iniciais: {registros_iniciais}")
        print(f"   Removidos {removidos} registros com valores ausentes\n")

        # Plot 4: antes/depois da limpeza
        plt.figure(figsize=(5,3))
        plt.bar(["Antes","Depois"], [registros_iniciais, len(self.dados_originais)], color=['red','green'])
        plt.title("Registros antes/depois da limpeza")
        plt.savefig("plot_etapa3_limpeza.png", dpi=100, bbox_inches='tight')
        plt.close()

    def etapa4_conversao_tipos(self):
        """
        ETAPA 4: CONVERS√ÉO DE TIPOS E FORMATA√á√ÉO
        
        Converte tipos de dados para formatos apropriados
        """
        print("\nETAPA 4: CONVERS√ÉO DE TIPOS E FORMATA√á√ÉO")
        print("-" * 50)

        # Plot 5: Tipos iniciais
        print("Tipos originais:")
        print(self.dados_originais.dtypes)

        # Exemplo de convers√µes
        bool_cols = ['win','mac','linux','steam_deck']
        for col in bool_cols:
            if col in self.dados_originais.columns:
                if self.dados_originais[col].dtype == bool:
                    print(f"{col}: bool ‚Üí int")
                self.dados_originais[col] = self.dados_originais[col].astype(int)
        
        # Converter colunas num√©ricas
        for c in ['user_reviews','price_final','price_original','discount','positive_ratio']:
            if c in self.dados_originais.columns:
                self.dados_originais[c] = pd.to_numeric(self.dados_originais[c], errors='coerce')

        print("\nTipos ap√≥s convers√£o:")
        print(self.dados_originais.dtypes)

        # Plot 6: Histograma colunas num√©ricas
        plt.figure(figsize=(8,5))
        self.dados_originais.select_dtypes(include=[np.number]).hist(figsize=(8,5))
        plt.tight_layout()
        plt.savefig("plot_etapa4_hist.png", dpi=100, bbox_inches='tight')
        plt.close()

    def etapa5_tratamento_outliers(self):
        """
        ETAPA 5: TRATAMENTO DE OUTLIERS
        
        Identifica e remove outliers das vari√°veis num√©ricas
        """
        print("\nETAPA 5: TRATAMENTO DE OUTLIERS")
        print("   M√©todo: IQR")
        print("-" * 50)

        num_cols = ['user_reviews','price_final','positive_ratio']
        df = self.dados_originais.copy()
        reg_iniciais = len(df)
        total_removidos = 0

        for col in num_cols:
            Q1 = df[col].quantile(0.25)
            Q3 = df[col].quantile(0.75)
            IQR = Q3 - Q1
            limite_inf = Q1 - 1.5*IQR
            limite_sup = Q3 + 1.5*IQR
            cond = (df[col] < limite_inf) | (df[col] > limite_sup)

            removidos = df[cond].shape[0]
            total_removidos += removidos
            df = df[~cond]
            print(f"   {col}: {removidos} outliers removidos")
            print(f"      Limites: [{limite_inf:.2f}, {limite_sup:.2f}]")

        self.dados_originais = df.reset_index(drop=True)
        print(f"\nRESUMO DO TRATAMENTO:")
        print(f"   Registros iniciais: {reg_iniciais}")
        print(f"   Outliers removidos: {total_removidos}")
        print(f"   Taxa de remo√ß√£o: {100*total_removidos/reg_iniciais:.2f}%")
        print(f"   Registros finais: {len(self.dados_originais)}")

        # Plot 7: Boxplots p√≥s-outliers
        plt.figure(figsize=(8,3))
        for i, col in enumerate(num_cols, 1):
            plt.subplot(1, len(num_cols), i)
            sns.boxplot(y=self.dados_originais[col], color='orange')
            plt.title(col)
        plt.tight_layout()
        plt.savefig("plot_etapa5_box.png", dpi=100, bbox_inches='tight')
        plt.close()

    def etapa6_codificacao_categoricas(self):
        """
        ETAPA 6: CODIFICA√á√ÉO DE VARI√ÅVEIS CATEG√ìRICAS
        
        Aplica Label Encoding para a vari√°vel target
        """
        print("\nETAPA 6: CODIFICA√á√ÉO DE VARI√ÅVEIS CATEG√ìRICAS")
        print("-" * 50)

        # Exemplo: Codificar "rating" ‚Üí self.y_final
        if 'rating' in self.dados_originais.columns:
            print("Codifica√ß√£o da vari√°vel target 'rating':")
            classes_unicas = self.dados_originais['rating'].unique()
            self.dados_originais['rating_encoded'] = self.le.fit_transform(self.dados_originais['rating'])

            # Print map
            for i, c_name in enumerate(self.le.classes_):
                print(f"   '{c_name}' ‚Üí {i}")

            num_classes = len(self.le.classes_)
            print(f"{num_classes} classes codificadas")
        else:
            print("   Nenhuma vari√°vel categ√≥rica 'rating' encontrada!")

        # Plot 8: Distribui√ß√£o da nova target
        if 'rating_encoded' in self.dados_originais.columns:
            plt.figure(figsize=(5,3))
            sns.countplot(x='rating_encoded', data=self.dados_originais)
            plt.title("Distribui√ß√£o de 'rating_encoded'")
            plt.savefig("plot_etapa6_cat.png", dpi=100, bbox_inches='tight')
            plt.close()

    def etapa7_escalonamento_variaveis(self):
        """
        ETAPA 7: ESCALONAMENTO DE VARI√ÅVEIS
        
        Aplica escalonamento robusto para lidar com outliers residuais
        """
        print("\nETAPA 7: ESCALONAMENTO DE VARI√ÅVEIS")
        print("   M√©todo: RobustScaler")
        print("-" * 50)

        # Selecionar features que N√ÉO causem vazamento
        # (Removendo 'positive_ratio' - suspeita de vazamento)
        colunas = []
        for c in ['user_reviews','price_final','win','mac','linux','steam_deck']:
            if c in self.dados_originais.columns:
                colunas.append(c)

        # Guardar em X_final e y_final
        self.X_final = self.dados_originais[colunas].copy()
        self.y_final = self.dados_originais['rating_encoded'].copy()

        print(f"Features selecionadas (sem positive_ratio): {list(self.X_final.columns)}")
        print(f"Dimens√µes X: {self.X_final.shape}")
        print(f"Dimens√µes y: {self.y_final.shape}")

        # Aqui apenas instanciamos no init (self.scaler).
        # Aplicaremos ap√≥s dividir treino/teste

        # Plot 9: Pairplot parcial (opcional)
        sns.pairplot(self.dados_originais, vars=colunas, hue='rating_encoded', corner=True, height=3)
        plt.savefig("plot_etapa7_pair.png", dpi=100, bbox_inches='tight')
        plt.close()

    def etapa8_selecao_atributos(self):
        """
        ETAPA 8: SELE√á√ÉO E CRIA√á√ÉO DE ATRIBUTOS
        
        Aplica sele√ß√£o de features e cria novos atributos
        """
        print("\nETAPA 8: SELE√á√ÉO E CRIA√á√ÉO DE ATRIBUTOS")
        print("-" * 50)
        X_enhanced = self.X_final.copy()

        print("Criando novos atributos:")
        # Exemplo: price_per_review
        if 'price_final' in X_enhanced.columns and 'user_reviews' in X_enhanced.columns:
            X_enhanced['price_per_review'] = X_enhanced['price_final'] / (X_enhanced['user_reviews'] + 1)
            print("   price_per_review: pre√ßo por review")
        
        # multi_platform_score
        plats = ['win','mac','linux','steam_deck']
        X_enhanced['multi_platform_score'] = 0
        for p in plats:
            if p in X_enhanced.columns:
                X_enhanced['multi_platform_score'] += X_enhanced[p]

        print("   multi_platform_score: suporte multi-plataforma")

        # log_reviews
        if 'user_reviews' in X_enhanced.columns:
            X_enhanced['log_reviews'] = np.log1p(X_enhanced['user_reviews'])
            print("   log_reviews: log da popularidade")

        # Plot 10: Correla√ß√£o das novas features
        plt.figure(figsize=(5,4))
        cor_mat = X_enhanced.corr()
        sns.heatmap(cor_mat, cmap='RdBu', center=0)
        plt.title("Correla√ß√£o ap√≥s cria√ß√£o de atributos")
        plt.savefig("plot_etapa8_attr.png", dpi=100, bbox_inches='tight')
        plt.close()

        # Atualizar X_final
        self.X_final = X_enhanced

    def etapa9_balanceamento_classes(self):
        """
        ETAPA 9: BALANCEAMENTO DE CLASSES (SMOTE)
        
        Aplica t√©cnicas para balancear distribui√ß√£o das classes
        """
        print("\nETAPA 9: BALANCEAMENTO DE CLASSES")
        print("   M√©todo: SMOTE")
        print("-" * 50)
        # (Aplicar s√≥ depois da divis√£o, mas podemos mostrar a distribui√ß√£o antes)
        dist = self.y_final.value_counts()
        print("Distribui√ß√£o atual das classes:")
        for c, qtd in dist.items():
            print(f"   Classe {c}: {qtd} ({100*qtd/len(self.y_final):.1f}%)")

        maxc = dist.max()
        minc = dist.min()
        print(f"\nAn√°lise do desbalanceamento:")
        print(f"   Classe minorit√°ria: {minc} amostras")
        print(f"   Classe majorit√°ria: {maxc} amostras")
        print(f"   Raz√£o de desbalanceamento: {maxc/minc:.2f}:1")

    def etapa10_reducao_dimensionalidade(self, aplicar=False):
        """
        ETAPA 10: REDU√á√ÉO DE DIMENSIONALIDADE
        
        Aplica PCA se necess√°rio (opcional para este dataset)
        """
        print("\nETAPA 10: REDU√á√ÉO DE DIMENSIONALIDADE")
        print(f"   Aplicar PCA: {aplicar}")
        print("-" * 50)
        if aplicar:
            print("   (EXEMPLO) PCA com 95% de vari√¢ncia explicada - n√£o implementado agora")
        else:
            print("   PCA n√£o aplicado (desnecess√°rio para este dataset)")

    def etapa11_divisao_dados(self, test_size=0.2, random_state=42):
        """
        ETAPA 11: DIVIS√ÉO DOS DADOS - SMOTE aplicado no treino
        
        Divide em treino/teste com estratifica√ß√£o
        """
        print("\nETAPA 11: DIVIS√ÉO DOS DADOS (CORRIGIDA)")
        print("-" * 50)
        X = self.X_final.copy()
        y = self.y_final.copy()

        # Split
        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(
            X, y, test_size=test_size, random_state=random_state, stratify=y
        )

        # Aplicar SMOTE s√≥ no treino
        print(f"\nAplicando SMOTE apenas no conjunto de treino...")
        smote = SMOTE(random_state=42, k_neighbors=5)
        X_train_bal, y_train_bal = smote.fit_resample(self.X_train, self.y_train)

        # Escalar
        self.X_train_scaled = self.scaler.fit_transform(X_train_bal)
        self.X_test_scaled = self.scaler.transform(self.X_test)

        print(f"   Treino original: {len(self.X_train):,}")
        print(f"   Treino balanceado: {len(X_train_bal):,}")
        print(f"   Teste (inalterado): {len(self.X_test):,}")

        # Atualizar
        self.X_train_scaled = pd.DataFrame(self.X_train_scaled, columns=X_train_bal.columns)
        self.X_test_scaled = pd.DataFrame(self.X_test_scaled, columns=self.X_test.columns, index=self.X_test.index)
        self.y_train = pd.Series(y_train_bal)
        
    def etapa12_treinamento_modelos(self):
        """
        ETAPA 12: TREINAMENTO DO MODELO
        
        Treina m√∫ltiplos modelos para compara√ß√£o
        """
        print("\nETAPA 12: TREINAMENTO DE MODELOS")
        print("-" * 50)
        modelos_config = {
            'MLP': MLPClassifier(
                hidden_layer_sizes=(50,),
                max_iter=500,
                random_state=42
            ),
            'Random Forest': RandomForestClassifier(
                n_estimators=100,
                max_depth=8,
                random_state=42
            ),
            'Gradient Boosting': GradientBoostingClassifier(
                n_estimators=100,
                learning_rate=0.1,
                max_depth=5,
                random_state=42
            ),
            'Logistic Regression': LogisticRegression(
                max_iter=1000,
                random_state=42
            )
        }

        print(f"Treinando {len(modelos_config)} modelos:\n")
        for nome, modelo in modelos_config.items():
            print(f"   Treinando {nome}...")
            try:
                modelo.fit(self.X_train_scaled, self.y_train)
                
                # Predi√ß√µes
                y_pred_train = modelo.predict(self.X_train_scaled)
                y_pred_test = modelo.predict(self.X_test_scaled)

                acc_train = accuracy_score(self.y_train, y_pred_train)
                acc_test  = accuracy_score(self.y_test, y_pred_test)
                f1_test   = f1_score(self.y_test, y_pred_test, average='weighted')

                self.modelos[nome] = {
                    'modelo': modelo,
                    'acc_train': acc_train,
                    'acc_test': acc_test,
                    'f1_score': f1_test
                }
                print(f"      ‚úÖ Acur√°cia Treino: {acc_train:.4f}")
                print(f"      ‚úÖ Acur√°cia Teste : {acc_test:.4f}")
                print(f"      ‚úÖ F1-Score       : {f1_test:.4f}\n")

            except Exception as e:
                print(f"      ‚ùå Erro: {e}")
        print(f"Treinamento conclu√≠do para {len(self.modelos)} modelos!")

    def etapa13_avaliacao_modelos(self):
        """
        ETAPA 13: AVALIA√á√ÉO DO MODELO
        
        Avalia todos os modelos treinados
        """
        print("\nETAPA 13: AVALIA√á√ÉO DE MODELOS")
        print("-" * 50)

        if not self.modelos:
            print("‚ùå Nenhum modelo treinado com sucesso!")
            return None

        print("COMPARA√á√ÉO DE DESEMPENHO:")
        print(f"{'Modelo':<20} {'Acc.Treino':<10} {'Acc.Teste':<10} {'F1-Score':<10} {'Overfit':<10}")
        print("-" * 60)
        
        melhor_f1 = 0
        melhor_modelo_nome = None
        for nome, m in self.modelos.items():
            overfit = m['acc_train'] - m['acc_test']
            if m['f1_score'] > melhor_f1:
                melhor_f1 = m['f1_score']
                melhor_modelo_nome = nome
            status = "Baixo"
            if overfit > 0.1:
                status = "Alto"
            elif overfit > 0.05:
                status = "M√©dio"

            print(f"{nome:<20} {m['acc_train']:<10.4f} {m['acc_test']:<10.4f} {m['f1_score']:<10.4f} {status:<10}")

        if melhor_modelo_nome is None:
            return None

        print(f"\nMELHOR MODELO: {melhor_modelo_nome}")
        print(f"   F1-Score: {melhor_f1:.4f}")

        self.melhor_modelo = self.modelos[melhor_modelo_nome]['modelo']
        return melhor_modelo_nome

    def etapa14_ajuste_hiperparametros(self, modelo_nome):
        """
        ETAPA 14: AJUSTE DE HIPERPAR√ÇMETROS
        
        Otimiza hiperpar√¢metros do melhor modelo
        """
        print("\nETAPA 14: AJUSTE DE HIPERPAR√ÇMETROS")
        print("-" * 50)
        if modelo_nome:
            print(f"Ajustando hiperpar√¢metros de {modelo_nome} (Exemplo simplificado)")
        else:
            print("‚ùå Nenhum modelo para ajustar.")
    
    def etapa15_testes_finais(self):
        """
        ETAPA 15: TESTES FINAIS E VALIDA√á√ÉO
        
        Realiza valida√ß√£o cruzada e testes finais
        """
        print("\nETAPA 15: TESTES FINAIS E VALIDA√á√ÉO")
        print("-" * 50)
        if self.melhor_modelo:
            y_pred_test = self.melhor_modelo.predict(self.X_test_scaled)
            final_f1 = f1_score(self.y_test, y_pred_test, average='weighted')
            print(f"F1-Score Final: {final_f1:.4f}")
            self.resultados_finais['metricas'] = {'f1_score': final_f1}
        else:
            print("‚ùå Nenhum modelo definido como melhor.")
    
    def gerar_relatorio_final(self):
        """
        Exibe um sum√°rio no final
        """
        if 'metricas' in self.resultados_finais:
            f1_final = self.resultados_finais['metricas']['f1_score']
            if f1_final >= 0.85:
                print(f"   Excelente desempenho (F1 ‚â• 0.85)")
            elif f1_final >= 0.75:
                print(f"   Bom desempenho (F1 ‚â• 0.75)")
            elif f1_final >= 0.65:
                print(f"   Desempenho moderado (F1 ‚â• 0.65)")
            else:
                print(f"   Desempenho abaixo do esperado")
            print(f"   Modelo pronto para produ√ß√£o!")
            print("\n" + "="*80)
            print("TRABALHO FINAL CONCLU√çDO COM SUCESSO!")
            print("="*80)
        else:
            print("\n‚ùå Projeto n√£o foi conclu√≠do devido a erros.")

    def executar_pipeline_completo(self):
        """
        Executa todo o pipeline do trabalho final
        """
        print("EXECUTANDO PIPELINE COMPLETO DO TRABALHO FINAL")
        print("=" * 80)
        try:
            if not self.etapa1_coleta_dados():
                return None
            self.etapa2_analise_exploratoria()
            self.etapa3_limpeza_dados()
            self.etapa4_conversao_tipos()
            self.etapa5_tratamento_outliers()
            self.etapa6_codificacao_categoricas()
            self.etapa7_escalonamento_variaveis()
            self.etapa8_selecao_atributos()
            self.etapa9_balanceamento_classes()
            self.etapa10_reducao_dimensionalidade(aplicar=False)
            self.etapa11_divisao_dados()
            self.etapa12_treinamento_modelos()
            melhor_modelo_nome = self.etapa13_avaliacao_modelos()
            self.etapa14_ajuste_hiperparametros(melhor_modelo_nome)
            self.etapa15_testes_finais()
            self.gerar_relatorio_final()
            return self.resultados_finais
        except Exception as e:
            print(f"‚ùå Erro durante execu√ß√£o do pipeline: {e}")
            import traceback
            traceback.print_exc()
            return None

def main():
    pipeline = PipelineTrabalhoFinal()
    resultados = pipeline.executar_pipeline_completo()
    if resultados:
        print(f"\nüèÜ PROJETO CONCLU√çDO COM SUCESSO!")
        print(f"F1-Score Final: {resultados['metricas']['f1_score']:.4f}")
    else:
        print(f"\n‚ùå Projeto n√£o foi conclu√≠do devido a erros.")

if __name__ == "__main__":
    main()
